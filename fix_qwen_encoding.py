#!/usr/bin/env python
"""
Fix script for Qwen model character encoding issues in multi-vision-toolkit.
This script enhances the text cleaning in BaseVisionModel.clean_output to handle
problematic character sequences in Qwen model output.
"""

import logging
import re
from models.base_model import BaseVisionModel

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("fix_encoding")

# Original clean_output function for reference
original_clean_output = BaseVisionModel.clean_output

def enhanced_clean_output(self, text: str) -> str:
    """
    Enhanced text cleaning function that specifically handles Qwen encoding issues.
    This function first applies the original cleaning method, then applies additional
    fixes specific to Qwen's character encoding problems.
    """
    try:
        # First use the original clean_output method
        cleaned_text = original_clean_output(self, text)
        
        # Additional fixes for Qwen-specific issues:
        
        # 1. Remove common problematic patterns seen in Qwen output
        patterns_to_remove = [
            # Original patterns
            r'<[Uu][Ff]unction[^>]*>',  # UFunction/ufunction tags
            r'<pair[^>]*>',             # <pair> tags
            r'[\u4E00-\u9FFF]{2,}',     # Sequences of multiple Chinese characters
            r'[\u0600-\u06FF]{2,}',     # Sequences of multiple Arabic characters
            r'[\u0900-\u097F]{2,}',     # Sequences of multiple Devanagari characters
            r'[\u0D80-\u0DFF]{2,}',     # Sequences of multiple Sinhala characters
            r'[\u1200-\u137F]{2,}',     # Sequences of multiple Ethiopic characters
            r'[\uAC00-\uD7AF]{2,}',     # Sequences of multiple Hangul characters
            r'[\u3040-\u30FF]{2,}',     # Sequences of multiple Hiragana/Katakana characters
            r'[^\x00-\x7F]{3,}',        # Any sequence of 3+ non-ASCII characters
            r'[\U00010000-\U0010FFFF]+', # Any supplementary Unicode characters (emojis, etc.)
            
            # New patterns based on provided example
            r'quitting\s+numeros',       # Matches pattern in the example
            r'randomized\s*‡∏™‡∏°',          # Thai character patterns
            r'mozilla\s+—Å–ø',             # Cyrillic mixed with Latin
            r'realidad\s+\(',            # Common pattern in the example
            r'--\[\s*[^\]]*\]',          # Matches bracket patterns like --[
            r'\$\(\'[^\']*\'',           # Matches JavaScript-like patterns
            r',[^,]{1,3}response',       # Suspicious short segments with "response"
            r'cluding',                  # Common garbled fragment
            r'current◊ñ◊®',                # Mixed scripts
            r'gi·∫øtifareetings',          # Vietnamese mixed with other characters
            r'verf√ºg◊ñ◊®',                 # German and Hebrew mixed
            r'angan captive',            # Common garbled pattern
            r'\(\[-[^\]]*\]',            # Matches [(- patterns
            r'\.Second[^\s]*',           # Common issue pattern
            r'\$\(\'?\.[^\']*',          # JavaScript-like patterns
            r'Categoria\s+carbohydrates', # Nonsensical combinations
            r'Prompt\(\)\]',             # Code-like fragments
            r'realidad\s+--',            # Another common pattern
            r'ctp-collapse',             # UI element references
            r'Framebuffer cont',         # Technical terms out of context
            r'\d+\.\d+\.\d+\.\d+',       # IP addresses
            r'mozillaguards',            # Browser references out of context
            r'[a-zA-Z]+\.trade\(',       # Code-like fragments
            r'periments realidad',       # Nonsensical combinations
            r'\([0-9]{3,}\)',            # Suspicious number sequences in parentheses
            r'[^\x00-\x7F]\d+[^\x00-\x7F]', # Non-ASCII + digits + non-ASCII
            r'@[a-zA-Z0-9]+\.[a-zA-Z]+',  # Email-like patterns without full address
            r'[^\s]+\.com\/[^\s]+',       # URL fragments
            r'[a-zA-Z]+-collapse',        # Bootstrap-like class names
            r'popover',                   # UI element terminology
            r'cushion reveal‡∏©ipt',        # Mixed script gibberish
            r'swagger',                   # API terminology out of context
            r'[a-zA-Z]+\.[a-zA-Z]+\([^)]*\)', # Method calls
            r'bean[a-z]+ipt'              # JavaScript-like references
        ]
        
        for pattern in patterns_to_remove:
            cleaned_text = re.sub(pattern, ' ', cleaned_text)
        
        # 2. Replace problematic character combinations
        char_replacements = {
            # Original replacements
            '.hpp': '',         # Common pattern seen in errors
            '.rand': '',        # Common pattern seen in errors
            '.getSharedPreferences': '',
            '.extern': '',      # Common pattern seen in errors
            '.byLObject': '',   # Common pattern seen in errors
            '/operator': '',    # Common pattern seen in errors
            '.ContentType': '', # Common pattern seen in errors
            'viewDidLoad': '',  # Common pattern seen in errors
            '.weixin': '',      # Common pattern seen in errors,
            
            # New replacements from the example
            'numeros': '',      # Common in garbled output
            'realidad': '',     # Common in garbled output
            'NASA': '',         # Appears in context-free places
            'carbohydrates': '',# Common in nonsensical combinations
            'mozilla': '',      # Browser references out of context
            'randomized': '',   # Common in problematic sequences
            'server': '',       # Common technical term out of context
            'Misc': '',         # Miscellaneous fragments
            'lan√ß': '',         # Partial words with diacritics
            'Prompt': '',       # Programming reference out of context
            'levels--': '',     # Technical pattern
            'cushion': '',      # Random words out of context
            'reveal': '',       # Common in problematic contexts
            'Categoria': '',    # Category references in wrong languages
            'swagger': '',      # API terminology out of context
            'popover': '',      # UI element terminology
            'response': '',     # Common in API-like gibberish
            'resale': '',       # Common in nonsensical text
            'Second': '',       # Common in problematic sequences
            'Rome': '',         # Location names out of context
            'Wilde': '',        # Names appearing randomly
            'Frame': '',        # UI terminology
            'equality': '',     # Conceptual terms out of context
            '--[': '',          # Code-like pattern starts
            ']--': '',          # Code-like pattern ends
            'collapse': ''      # UI component terminology
        }
        
        for old, new in char_replacements.items():
            cleaned_text = cleaned_text.replace(old, new)
        
        # 3. Normalize whitespace again after our aggressive cleaning
        cleaned_text = ' '.join(cleaned_text.split())
        
        # 4. Verify text is still valid UTF-8
        try:
            # Force encoding and decoding to ensure valid UTF-8
            cleaned_text = cleaned_text.encode('utf-8', errors='replace').decode('utf-8')
        except Exception as e:
            logger.error(f"UTF-8 conversion error: {e}")
            # Fallback to ASCII-only if UTF-8 conversion fails
            cleaned_text = ''.join(c if ord(c) < 128 else ' ' for c in cleaned_text)
        
        return cleaned_text.strip()
        
    except Exception as e:
        logger.error(f"Enhanced clean_output failed: {e}")
        # Fallback to original method or simplest possible cleaning if that fails
        try:
            return original_clean_output(self, text)
        except:
            # Ultimate fallback: return ASCII-only text
            if not isinstance(text, str):
                return "Error: Text cleaning failed completely."
            return ''.join(c if ord(c) < 128 else ' ' for c in text).strip()

def apply_encoding_fix():
    """
    Apply the encoding fix by monkey-patching the BaseVisionModel.clean_output method.
    """
    logger.info("Applying Qwen encoding fix...")
    
    # Replace the clean_output method with our enhanced version
    BaseVisionModel.clean_output = enhanced_clean_output
    
    logger.info("Encoding fix applied successfully.")
    return True

def test_encoding_fix():
    """
    Test the encoding fix with a sample problematic text.
    """
    logger.info("Testing encoding fix with sample problematic text...")
    
    # Sample text with encoding issues similar to those seen in Qwen output
    test_text = """Description: Todos<pair„Åæ„Åü a≈üama.hpp.hpp·ã∂ n√§r GulÈ™ã/operator‰∏∫‰∫Ü.getSharedPreferencesstead‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î seznam(repoabiesedic Voice consolesË∞ÉÂâÇ liquidworldËΩ¥Êâø\JsonüçènestjsÂ•πÁöÑ)viewDidLoad fulfilËÜänestjs´çΩ´çΩÂ≠óÁ¨¶‰∏≤ ÿßŸÑŸÅŸÜÿßŸÜ eventName callback SchoolsÁâπ‰∫ßÂº∫ÂõΩITIONALÊÉ≥Ë±°},{ ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î.extern.weixin Returned Ïñ∏ slate eventName("{\"("{\"ocrine closeButtonFFFF.randTodosÊó©Âú®HandlerContext noop ReduxÂ®â fulfilUMÔøΩ a≈üama LeedsË∞àËØù –õ—é Voltage "\<◊í◊ï◊£ANTS},{ ‡πè‰Ω†ÊòØ\Json Returned n√§rÂÆπÁ∫≥„Åæ„Åü VoltageHandlerContext stddevocrine scored a≈üama.getSharedPreferences n√§r liquid Cong Believe ReturnedÊæõ eventName_descriptionXi‰∏∫‰∫Ü con: Router ReturnedANTAfigures n√§r_True seznam.ContentType RecruÁ∫∞ Nested seznam)viewDidLoad/operator.randÊ∑±‰∫§Ëøô‰∏Ä Annex possess yaƒü·õÖÂç≥Â∞Ü yaƒü‰∫∫„ÅØ Returned caract√®re"""
    
    # Create a minimal BaseVisionModel for testing
    class TestModel(BaseVisionModel):
        def _setup_model(self):
            pass
        def analyze_image(self, image_path, quality="standard"):
            pass
        def analyze_images_batch(self, image_paths, quality="standard"):
            pass
    
    # Save original method to restore later
    original_method = BaseVisionModel.clean_output
    
    try:
        # Apply the fix
        apply_encoding_fix()
        
        # Create model instance and test
        model = TestModel()
        cleaned = model.clean_output(test_text)
        
        # Check if common problematic patterns were removed
        success = True
        if ".hpp" in cleaned or ".rand" in cleaned or "/operator" in cleaned:
            logger.error("FAILURE: Common problematic patterns still present")
            success = False
        
        # Count non-ASCII characters before and after
        orig_non_ascii = sum(1 for c in test_text if ord(c) > 127)
        cleaned_non_ascii = sum(1 for c in cleaned if ord(c) > 127)
        
        logger.info(f"Original text length: {len(test_text)}")
        logger.info(f"Cleaned text length: {len(cleaned)}")
        logger.info(f"Non-ASCII characters in original: {orig_non_ascii}")
        logger.info(f"Non-ASCII characters in cleaned: {cleaned_non_ascii}")
        
        if cleaned_non_ascii < orig_non_ascii:
            logger.info("SUCCESS: Reduced non-ASCII characters")
        else:
            logger.warning("WARNING: Non-ASCII character count not reduced")
            success = False
        
        logger.info("\nOriginal text:")
        logger.info(test_text[:100] + "..." if len(test_text) > 100 else test_text)
        
        logger.info("\nCleaned text:")
        logger.info(cleaned[:100] + "..." if len(cleaned) > 100 else cleaned)
        
        return success
        
    finally:
        # Restore original method
        BaseVisionModel.clean_output = original_method

if __name__ == "__main__":
    print("Multi-Vision Toolkit - Fix Qwen Encoding Issues")
    print("-----------------------------------------------")
    
    # Test the fix first
    if test_encoding_fix():
        print("\nEncoding fix test successful!")
    else:
        print("\nEncoding fix test produced warnings, but can still be applied.")
    
    # Apply the fix
    if apply_encoding_fix():
        print("\nQwen encoding fix has been applied.")
        print("This fix will remain active for the current session.")
        print("To make it permanent, import this module in your code:")
        print("  from fix_qwen_encoding import apply_encoding_fix")
        print("  apply_encoding_fix()")
    else:
        print("\nFailed to apply encoding fix.")